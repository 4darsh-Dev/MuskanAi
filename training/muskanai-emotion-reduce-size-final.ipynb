{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install datasets transformers -q\n!pip3 install wandb --upgrade -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-23T13:25:30.567979Z","iopub.execute_input":"2024-04-23T13:25:30.568626Z","iopub.status.idle":"2024-04-23T13:25:54.889286Z","shell.execute_reply.started":"2024-04-23T13:25:30.568591Z","shell.execute_reply":"2024-04-23T13:25:54.888094Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm\n\nfrom datasets import load_dataset\nimport random\nfrom sklearn import metrics, model_selection, preprocessing\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport transformers\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nimport wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:25:54.891578Z","iopub.execute_input":"2024-04-23T13:25:54.891966Z","iopub.status.idle":"2024-04-23T13:26:59.896147Z","shell.execute_reply.started":"2024-04-23T13:25:54.891915Z","shell.execute_reply":"2024-04-23T13:26:59.895209Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def seed_everything(seed=73):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    # some cudnn methods can be random even after fixing the seed unless you tell it to be deterministic\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(1234)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:26:59.897238Z","iopub.execute_input":"2024-04-23T13:26:59.897756Z","iopub.status.idle":"2024-04-23T13:26:59.905737Z","shell.execute_reply.started":"2024-04-23T13:26:59.897731Z","shell.execute_reply":"2024-04-23T13:26:59.905062Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'random', #grid, random, bayesian\n    'metric': {\n      'name': 'auc_score',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n\n        'learning_rate': {\n            'values': [5e-5, 3e-5]\n        },\n        'batch_size': {\n            'values': [32, 64]\n        },\n        'epochs':{'value': 5},\n        'dropout':{\n            'values': [0.3, 0.4, 0.5]\n        },\n        'tokenizer_max_len': {'value': 40},\n    }\n}\n\nsweep_defaults = {\n    'learning_rate': 3e-5,\n    'batch_size': 64,\n    'epochs': 5,\n    'dropout': 0.3,\n    'tokenizer_max_len': 40\n}\n\nsweep_id = wandb.sweep(sweep_config, project='bhaavna')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:26:59.907724Z","iopub.execute_input":"2024-04-23T13:26:59.908023Z","iopub.status.idle":"2024-04-23T13:27:23.361204Z","shell.execute_reply.started":"2024-04-23T13:26:59.908000Z","shell.execute_reply":"2024-04-23T13:27:23.360269Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Create sweep with ID: 3f7ldnfx\nSweep URL: https://wandb.ai/solve-ease/bhaavnaye/sweeps/3f7ldnfx\n","output_type":"stream"}]},{"cell_type":"code","source":"go_emotions = load_dataset(\"go_emotions\")\ndata = go_emotions.data","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:23.362357Z","iopub.execute_input":"2024-04-23T13:27:23.362643Z","iopub.status.idle":"2024-04-23T13:27:28.699714Z","shell.execute_reply.started":"2024-04-23T13:27:23.362618Z","shell.execute_reply":"2024-04-23T13:27:28.698816Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/9.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a3bf9e1d8e4ac38e48eeb7d184ff09"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 2.77M/2.77M [00:00<00:00, 11.9MB/s]\nDownloading data: 100%|██████████| 350k/350k [00:00<00:00, 3.09MB/s]\nDownloading data: 100%|██████████| 347k/347k [00:00<00:00, 3.40MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7ca1030683947fbba8ce81d1824d540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40495c2d2b25429c85af10f35178ac81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36928cf8d0434fe68af1d0dfed5e8304"}},"metadata":{}}]},{"cell_type":"code","source":"train, valid, test = data[\"train\"].to_pandas(), data[\"validation\"].to_pandas(), data[\"test\"].to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:28.700957Z","iopub.execute_input":"2024-04-23T13:27:28.701332Z","iopub.status.idle":"2024-04-23T13:27:28.991329Z","shell.execute_reply.started":"2024-04-23T13:27:28.701299Z","shell.execute_reply":"2024-04-23T13:27:28.990285Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"mapping = {\n    0:\"admiration\",\n    1:\"amusement\",\n    2:\"anger\",\n    3:\"annoyance\",\n    4:\"approval\",\n    5:\"caring\",\n    6:\"confusion\",\n    7:\"curiosity\",\n    8:\"desire\",\n    9:\"disappointment\",\n    10:\"disapproval\",\n    11:\"disgust\",\n    12:\"embarrassment\",\n    13:\"excitement\",\n    14:\"fear\",\n    15:\"gratitude\",\n    16:\"grief\",\n    17:\"joy\",\n    18:\"love\",\n    19:\"nervousness\",\n    20:\"optimism\",\n    21:\"pride\",\n    22:\"realization\",\n    23:\"relief\",\n    24:\"remorse\",\n    25:\"sadness\",\n    26:\"surprise\",\n    27:\"neutral\",\n}\n\nn_labels = len(mapping)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:28.992572Z","iopub.execute_input":"2024-04-23T13:27:28.993227Z","iopub.status.idle":"2024-04-23T13:27:29.000878Z","shell.execute_reply.started":"2024-04-23T13:27:28.993191Z","shell.execute_reply":"2024-04-23T13:27:28.999998Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def one_hot_encoder(df):\n    one_hot_encoding = []\n    for i in tqdm(range(len(df))):\n        temp = [0]*n_labels\n        label_indices = df.iloc[i][\"labels\"]\n        for index in label_indices:\n            temp[index] = 1\n        one_hot_encoding.append(temp)\n    return pd.DataFrame(one_hot_encoding)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:29.002351Z","iopub.execute_input":"2024-04-23T13:27:29.002679Z","iopub.status.idle":"2024-04-23T13:27:29.016835Z","shell.execute_reply.started":"2024-04-23T13:27:29.002648Z","shell.execute_reply":"2024-04-23T13:27:29.016128Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_ohe_labels = one_hot_encoder(train)\nvalid_ohe_labels = one_hot_encoder(valid)\ntest_ohe_labels = one_hot_encoder(test)\ntrain_ohe_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:29.017794Z","iopub.execute_input":"2024-04-23T13:27:29.018081Z","iopub.status.idle":"2024-04-23T13:27:31.889887Z","shell.execute_reply.started":"2024-04-23T13:27:29.018058Z","shell.execute_reply":"2024-04-23T13:27:31.888880Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/43410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff02c1eb51b348fe972c9121428f3300"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5426 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4209fd1d27ab47a19d31d4cd7320386e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5427 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a6a02251e4456c83c4f73dc5829a64"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(43410, 28)"},"metadata":{}}]},{"cell_type":"code","source":"train = pd.concat([train, train_ohe_labels], axis=1)\nvalid = pd.concat([valid, valid_ohe_labels], axis=1)\ntest = pd.concat([test, test_ohe_labels], axis=1)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:31.892682Z","iopub.execute_input":"2024-04-23T13:27:31.893072Z","iopub.status.idle":"2024-04-23T13:27:31.926534Z","shell.execute_reply.started":"2024-04-23T13:27:31.893045Z","shell.execute_reply":"2024-04-23T13:27:31.925638Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                text labels       id  0  1  2  \\\n0  My favourite food is anything I didn't have to...   [27]  eebbqej  0  0  0   \n1  Now if he does off himself, everyone will thin...   [27]  ed00q6i  0  0  0   \n2                     WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj  0  0  1   \n3                        To make her feel threatened   [14]  ed7ypvh  0  0  0   \n4                             Dirty Southern Wankers    [3]  ed0bdzj  0  0  0   \n\n   3  4  5  6  ...  18  19  20  21  22  23  24  25  26  27  \n0  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   1  \n1  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   1  \n2  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n3  0  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n4  1  0  0  0  ...   0   0   0   0   0   0   0   0   0   0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n      <th>id</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>...</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>[27]</td>\n      <td>eebbqej</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>[27]</td>\n      <td>ed00q6i</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>[2]</td>\n      <td>eezlygj</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>[14]</td>\n      <td>ed7ypvh</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>[3]</td>\n      <td>ed0bdzj</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def inspect_category_wise_data(label, n=5):\n    samples = train[train[label] == 1].sample(n)\n    sentiment = mapping[label]\n    \n    print(f\"{n} samples from {sentiment} sentiment: \\n\")\n    for text in samples[\"text\"]:\n        print(text, end='\\n\\n')\n## inspecting data\ninspect_category_wise_data(4)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:31.927595Z","iopub.execute_input":"2024-04-23T13:27:31.927884Z","iopub.status.idle":"2024-04-23T13:27:31.938959Z","shell.execute_reply.started":"2024-04-23T13:27:31.927860Z","shell.execute_reply":"2024-04-23T13:27:31.938007Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"5 samples from approval sentiment: \n\nYeah dude I like the brown sugar ones a lot, what’s the problem?\n\nYes. Combined.\n\nCompletely understandable. Maybe mom should book flights a little bit farther in advance next time though!\n\nDoesn't mean any of those thing you liked are going to change. Not immediately anyways.\n\nAh ok! I figured I was getting it wrong.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class GoEmotionDataset:\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        label = self.labels[index]\n\n        inputs = self.tokenizer.__call__(text,\n                                        None,\n                                        add_special_tokens=True,\n                                        max_length=self.max_len,\n                                        padding=\"max_length\",\n                                        truncation=True,\n                                        )\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n\n        return {\n            \"ids\": torch.tensor(ids, dtype=torch.long),\n            \"mask\": torch.tensor(mask, dtype=torch.long),\n            \"labels\": torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:31.940285Z","iopub.execute_input":"2024-04-23T13:27:31.940655Z","iopub.status.idle":"2024-04-23T13:27:31.949690Z","shell.execute_reply.started":"2024-04-23T13:27:31.940622Z","shell.execute_reply":"2024-04-23T13:27:31.948805Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class GoEmotionClassifier(nn.Module):\n    def __init__(self, n_train_steps, n_classes, do_prob, bert_model):\n        super(GoEmotionClassifier, self).__init__()\n        self.bert = bert_model\n        self.dropout = nn.Dropout(do_prob)\n        self.out = nn.Linear(768, n_classes)\n        self.n_train_steps = n_train_steps\n        self.step_scheduler_after = \"batch\"\n\n    def forward(self, ids, mask):\n        output_1 = self.bert(ids, attention_mask=mask)[\"pooler_output\"]\n        output_2 = self.dropout(output_1)\n        output = self.out(output_2)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:31.950723Z","iopub.execute_input":"2024-04-23T13:27:31.951029Z","iopub.status.idle":"2024-04-23T13:27:31.965655Z","shell.execute_reply.started":"2024-04-23T13:27:31.951005Z","shell.execute_reply":"2024-04-23T13:27:31.964825Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.SqueezeBertTokenizer.from_pretrained(\"squeezebert/squeezebert-uncased\", do_lower_case=True)\n\ndef build_dataset(tokenizer_max_len):\n    train_dataset = GoEmotionDataset(train.text.tolist(), train[range(n_labels)].values.tolist(), tokenizer, tokenizer_max_len)\n    valid_dataset = GoEmotionDataset(valid.text.tolist(), valid[range(n_labels)].values.tolist(), tokenizer, tokenizer_max_len)\n    \n    return train_dataset, valid_dataset\n\ndef build_dataloader(train_dataset, valid_dataset, batch_size):\n    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n\n    return train_data_loader, valid_data_loader\n\ndef ret_model(n_train_steps, do_prob):\n  model = GoEmotionClassifier(n_train_steps, n_labels, do_prob, bert_model=bert_model)\n  return model","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:31.966775Z","iopub.execute_input":"2024-04-23T13:27:31.967182Z","iopub.status.idle":"2024-04-23T13:27:33.639594Z","shell.execute_reply.started":"2024-04-23T13:27:31.967151Z","shell.execute_reply":"2024-04-23T13:27:33.638587Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd9981c3ec74e128299dd5db69f7b3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"115a41ed461f4cf1b27e5fc587fb4099"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/500 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0553a6f8e522444981b47eb372325ad3"}},"metadata":{}}]},{"cell_type":"code","source":"sample_train_dataset, _ = build_dataset(40)\nprint(sample_train_dataset[0])\nlen(sample_train_dataset)\n# loading model\nbert_model = transformers.SqueezeBertModel.from_pretrained(\"squeezebert/squeezebert-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:33.640825Z","iopub.execute_input":"2024-04-23T13:27:33.641128Z","iopub.status.idle":"2024-04-23T13:27:36.028302Z","shell.execute_reply.started":"2024-04-23T13:27:33.641104Z","shell.execute_reply":"2024-04-23T13:27:36.027420Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{'ids': tensor([ 101, 2026, 8837, 2833, 2003, 2505, 1045, 2134, 1005, 1056, 2031, 2000,\n        5660, 2870, 1012,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0]), 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1])}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/103M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ed0ed7da9248c8941358597540aed6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"def ret_optimizer(model):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\"]\n    optimizer_parameters = [\n        {\n            \"params\": [\n                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.001,\n        },\n        {\n            \"params\": [\n                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.0,\n        },\n    ]\n    opt = AdamW(optimizer_parameters, lr=wandb.config.learning_rate)\n    return opt\n\ndef ret_scheduler(optimizer, num_train_steps):\n    sch = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n    return sch\n\ndef loss_fn(outputs, labels):\n    if labels is None:\n        return None\n    return nn.BCEWithLogitsLoss()(outputs, labels.float())\n\ndef log_metrics(preds, labels):\n    preds = torch.stack(preds)\n    preds = preds.cpu().detach().numpy()\n    labels = torch.stack(labels)\n    labels = labels.cpu().detach().numpy()\n    fpr_micro, tpr_micro, _ = metrics.roc_curve(labels.ravel(), preds.ravel())\n    \n    auc_micro = metrics.auc(fpr_micro, tpr_micro)\n    return {\"auc_micro\": auc_micro}","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:36.029754Z","iopub.execute_input":"2024-04-23T13:27:36.030643Z","iopub.status.idle":"2024-04-23T13:27:36.040091Z","shell.execute_reply.started":"2024-04-23T13:27:36.030612Z","shell.execute_reply":"2024-04-23T13:27:36.038989Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, device, scheduler):\n    train_loss = 0.0\n    model.train()\n    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n        ids = d[\"ids\"]\n        mask = d[\"mask\"]\n        targets = d[\"labels\"]\n\n        ids = ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets = targets.to(device, dtype=torch.float)\n\n        optimizer.zero_grad()\n        outputs = model(ids=ids, mask=mask)\n\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        train_loss += loss.item()\n        optimizer.step()\n        scheduler.step()\n    return train_loss\n    \n\ndef eval_fn(data_loader, model, device):\n    eval_loss = 0.0\n    model.eval()\n    fin_targets = []\n    fin_outputs = []\n    with torch.no_grad():\n        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n            ids = d[\"ids\"]\n            mask = d[\"mask\"]\n            targets = d[\"labels\"]\n\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            targets = targets.to(device, dtype=torch.float)\n\n            outputs = model(ids=ids, mask=mask)\n            loss = loss_fn(outputs, targets)\n            eval_loss += loss.item()\n            fin_targets.extend(targets)\n            fin_outputs.extend(torch.sigmoid(outputs))\n    return eval_loss, fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:36.041455Z","iopub.execute_input":"2024-04-23T13:27:36.041825Z","iopub.status.idle":"2024-04-23T13:27:36.056889Z","shell.execute_reply.started":"2024-04-23T13:27:36.041793Z","shell.execute_reply":"2024-04-23T13:27:36.055974Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def trainer(config=None):\n    with wandb.init(config=config):\n        config = wandb.config\n\n        train_dataset, valid_dataset = build_dataset(config.tokenizer_max_len)\n        train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config.batch_size)\n        print(\"Length of Train Dataloader: \", len(train_data_loader))\n        print(\"Length of Valid Dataloader: \", len(valid_data_loader))\n\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n        n_train_steps = int(len(train_dataset) / config.batch_size * 10)\n\n        model = ret_model(n_train_steps, config.dropout)\n        optimizer = ret_optimizer(model)\n        scheduler = ret_scheduler(optimizer, n_train_steps)\n        model.to(device)\n        model = nn.DataParallel(model)\n        wandb.watch(model)\n        \n        n_epochs = config.epochs\n\n        best_val_loss = 100\n        for epoch in tqdm(range(n_epochs)):\n            train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler)\n            eval_loss, preds, labels = eval_fn(valid_data_loader, model, device)\n          \n            auc_score = log_metrics(preds, labels)[\"auc_micro\"]\n            print(\"AUC score: \", auc_score)\n            avg_train_loss, avg_val_loss = train_loss / len(train_data_loader), eval_loss / len(valid_data_loader)\n            wandb.log({\n                \"epoch\": epoch + 1,\n                \"train_loss\": avg_train_loss,\n                \"val_loss\": avg_val_loss,\n                \"auc_score\": auc_score,\n            })\n            print(\"Average Train loss: \", avg_train_loss)\n            print(\"Average Valid loss: \", avg_val_loss)\n\n            # Save model at each epoch\n            model_save_path = f\"/kaggle/working/model_epoch_{epoch + 1}.pt\"\n            torch.save(model.state_dict(), model_save_path)  \n            print(\"Model saved for epoch \", epoch + 1, \" at \", model_save_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:36.058101Z","iopub.execute_input":"2024-04-23T13:27:36.058587Z","iopub.status.idle":"2024-04-23T13:27:36.077352Z","shell.execute_reply.started":"2024-04-23T13:27:36.058555Z","shell.execute_reply":"2024-04-23T13:27:36.076398Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"wandb.agent(sweep_id, function=trainer, count=1)\n!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-04-23T13:27:36.078500Z","iopub.execute_input":"2024-04-23T13:27:36.078775Z","iopub.status.idle":"2024-04-23T13:54:02.677732Z","shell.execute_reply.started":"2024-04-23T13:27:36.078751Z","shell.execute_reply":"2024-04-23T13:54:02.676361Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: agyfec29 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttokenizer_max_len: 40\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m4darsh-dev\u001b[0m (\u001b[33msolve-ease\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240423_132738-agyfec29</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/solve-ease/bhaavnaye/runs/agyfec29' target=\"_blank\">volcanic-sweep-1</a></strong> to <a href='https://wandb.ai/solve-ease/bhaavnaye' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/solve-ease/bhaavnaye/sweeps/3f7ldnfx' target=\"_blank\">https://wandb.ai/solve-ease/bhaavnaye/sweeps/3f7ldnfx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/solve-ease/bhaavnaye' target=\"_blank\">https://wandb.ai/solve-ease/bhaavnaye</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/solve-ease/bhaavnaye/sweeps/3f7ldnfx' target=\"_blank\">https://wandb.ai/solve-ease/bhaavnaye/sweeps/3f7ldnfx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/solve-ease/bhaavnaye/runs/agyfec29' target=\"_blank\">https://wandb.ai/solve-ease/bhaavnaye/runs/agyfec29</a>"},"metadata":{}},{"name":"stdout","text":"Length of Train Dataloader:  1357\nLength of Valid Dataloader:  170\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d2e691227844e558cee60ca7757221b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1357 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b19d44b3a53340be8d23300c6873bf70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbffcfbb93f7456abe44ef921de23202"}},"metadata":{}},{"name":"stdout","text":"AUC score:  0.9081048621303915\nAverage Train loss:  0.15828079863690944\nAverage Valid loss:  0.10932543623973341\nModel saved for epoch  1  at  /kaggle/working/model_epoch_1.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1357 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52a364291c254017941421e7c4d8cb03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"121a8e25c3d449bb84cc7b5e8dddcd42"}},"metadata":{}},{"name":"stdout","text":"AUC score:  0.9408515863686892\nAverage Train loss:  0.1020646705377954\nAverage Valid loss:  0.09403534549124101\nModel saved for epoch  2  at  /kaggle/working/model_epoch_2.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1357 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a87d6d4c79324e0e8ac3e1d86b714ce4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e66e20bac764c39853c0ab0e10530c8"}},"metadata":{}},{"name":"stdout","text":"AUC score:  0.9474723847686484\nAverage Train loss:  0.08991102965420981\nAverage Valid loss:  0.0881552437429919\nModel saved for epoch  3  at  /kaggle/working/model_epoch_3.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1357 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be93908d50ea415796796069914704fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc6b0f60b8ed453795f8c9b5baf0ad9b"}},"metadata":{}},{"name":"stdout","text":"AUC score:  0.9503246351719019\nAverage Train loss:  0.08301804252325742\nAverage Valid loss:  0.08746834193520686\nModel saved for epoch  4  at  /kaggle/working/model_epoch_4.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1357 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49b5669acbe747ce8798e816fac34faf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaf876c11dc840b6b513918c0d3862d9"}},"metadata":{}},{"name":"stdout","text":"AUC score:  0.9521776655050854\nAverage Train loss:  0.07772402463147284\nAverage Valid loss:  0.08653878335128812\nModel saved for epoch  5  at  /kaggle/working/model_epoch_5.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_score</td><td>▁▆▇██</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_loss</td><td>█▃▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_score</td><td>0.95218</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>0.07772</td></tr><tr><td>val_loss</td><td>0.08654</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">volcanic-sweep-1</strong> at: <a href='https://wandb.ai/solve-ease/bhaavnaye/runs/agyfec29' target=\"_blank\">https://wandb.ai/solve-ease/bhaavnaye/runs/agyfec29</a><br/> View project at: <a href='https://wandb.ai/solve-ease/bhaavnaye' target=\"_blank\">https://wandb.ai/solve-ease/bhaavnaye</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240423_132738-agyfec29/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}